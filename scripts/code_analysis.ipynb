{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports and definitions\n",
    "\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "import collections\n",
    "import re\n",
    "import os\n",
    "import git\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import glob\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 999)\n",
    "\n",
    "\n",
    "def analyze_obj(fobj):\n",
    "    # Print all methods and variables of object\n",
    "    for x in dir(fobj):\n",
    "        if \"_RObjectMixin\" in x:\n",
    "            continue\n",
    "        print(x)\n",
    "        print(eval(\"fobj.\" + x))\n",
    "        try:\n",
    "            print(eval(\"fobj.\" + x + \"()\"))\n",
    "        except:\n",
    "            pass\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "\n",
    "def analyze_library(source_path, verbose=True):\n",
    "    # Analyze R source code file\n",
    "    # Return dict with keys = top level function / variable names\n",
    "    if verbose:\n",
    "        print(\"Anayzing \" + source_path)\n",
    "\n",
    "    r_source = robjects.r['source']\n",
    "    r_source(source_path)\n",
    "    \n",
    "    with open(source_path, \"r\") as f:\n",
    "        source_lines = f.readlines()\n",
    "\n",
    "    source_lines = [x.replace(\"\\n\", \"\") for x in source_lines]\n",
    "    fdict = {}\n",
    "    for fname, fobj in robjects.globalenv.items():\n",
    "        fdict[fname] = collections.defaultdict()\n",
    "        fdict[fname][\"obj\"] = fobj\n",
    "        fdict[fname][\"type_label\"] = fobj.rclass[0]\n",
    "        fdict[fname][\"type_technical\"] = fobj.typeof\n",
    "\n",
    "        fdict[fname][\"code_raw\"] = fobj.r_repr()\n",
    "\n",
    "        if fdict[fname][\"type_label\"] == \"function\":\n",
    "            fdict[fname][\"params\"] = {}\n",
    "            try:\n",
    "                for param in fobj.formals():\n",
    "                    param_default = param.r_repr().split(\"= \")[1][:-1]\n",
    "                    if param_default == \"\":\n",
    "                        param_default = None       \n",
    "                    fdict[fname][\"params\"][param.names.r_repr().replace('\"', '')] = param_default\n",
    "            except TypeError as e:\n",
    "                # Case if function has no parameters\n",
    "                if e.__str__() != \"'NULLType' object is not iterable\":\n",
    "                    raise\n",
    "            fdict[fname][\"params_count\"] = len([x for x in fdict[fname][\"params\"].values()])\n",
    "            fdict[fname][\"params_obligatory_count\"] = len([x for x in fdict[fname][\"params\"].values() if x is None])\n",
    "            fdict[fname][\"params_optional_count\"] = len([x for x in fdict[fname][\"params\"].values() if x is not None])\n",
    "\n",
    "            fdict[fname][\"code_content_str\"] = re.sub(\"(\\n$)|(^\\n)\", \"\", re.sub(r\"(^[^{]*{)|(}[^}]*$)\", \"\", fdict[fname][\"code_raw\"]))\n",
    "            code_lines = fdict[fname][\"code_content_str\"].split(\"\\n\")\n",
    "            fdict[fname][\"code_lines_count\"] = len(code_lines) - 1\n",
    "\n",
    "            f_starts = [i for i, line in enumerate(source_lines) if re.match(fname+\"=function\\(\", line.replace(\" \", \"\").replace(\"<-\", \"=\"))]\n",
    "            if len(f_starts) > 1:\n",
    "                print(\"Warning ! Function '\" + fname + \"' defined multiple times: \" + str(f_starts))\n",
    "                for start in f_starts:\n",
    "                    print(source_lines[start])\n",
    "            elif len(f_starts) == 0:\n",
    "                print(fdict)\n",
    "                raise ValueError(\"Function not found: \" + fname)\n",
    "            fdict[fname][\"code_starts\"] = f_starts\n",
    "            fdict[fname][\"code_start\"] = f_starts[-1]\n",
    "            fdict[fname][\"out\"] = re.findall(\"return\\([^\\)]*\\)\", fdict[fname][\"code_content_str\"])\n",
    "\n",
    "            fdict[fname][\"params_unused\"] = []\n",
    "            for param in fdict[fname][\"params\"]:\n",
    "                # Param is only used if: \n",
    "                # a) it is in the function code, \n",
    "                # b) it is not precedented or followed by a char or number\n",
    "                # c) in the same line there is no # left of the param name\n",
    "                if re.search(\"(^|\\n)[^#\\n]*[^a-zA-Z0-9#\\n]\" + param + \"[^a-zA-Z0-9]\", fdict[fname][\"code_content_str\"]) is None:\n",
    "                    fdict[fname][\"params_unused\"] += [param]\n",
    "\n",
    "        elif fdict[fname][\"type_label\"] == \"matrix\":\n",
    "            fdict[fname][\"matrix_dim\"] = fobj.dim\n",
    "            fdict[fname][\"matrix_dim_names\"] = fobj.dimnames\n",
    "            fdict[fname][\"matrix_col_names\"] = fobj.colnames\n",
    "            fdict[fname][\"matrix_col_count\"] = fobj.ncol\n",
    "            fdict[fname][\"matrix_row_count\"] = fobj.nrow\n",
    "            fdict[fname][\"matrix_len\"] = fobj.__len__()\n",
    "            fdict[fname][\"matrix_content\"] = fobj.__str__()\n",
    "            fdict[fname][\"matrix_factors\"] = fobj.factor()\n",
    "\n",
    "    f_starts = [x for val in fdict.values() if val[\"type_label\"] == \"function\"  for x in val[\"code_starts\"]]\n",
    "    f_starts += [len(source_lines)]\n",
    "    f_end_indexs = []\n",
    "\n",
    "    for start in f_starts:\n",
    "        for i, line in enumerate(reversed(source_lines[0:start])):\n",
    "            if \"}\" in line or \"function(\" in line:\n",
    "                f_end_indexs += [start-i-1]\n",
    "                break\n",
    "\n",
    "    for fname, val in fdict.items():\n",
    "        if val[\"type_label\"] == \"function\":\n",
    "            fdict[fname][\"code_end\"] = min([x for x in f_end_indexs if x >= val[\"code_start\"]])        \n",
    "            fdict[fname][\"code_with_comments_lines_count\"] = fdict[fname][\"code_end\"] - fdict[fname][\"code_start\"] + 1\n",
    "            fdict[fname][\"comments_lines_count\"] = max(0, fdict[fname][\"code_with_comments_lines_count\"] - fdict[fname][\"code_lines_count\"] - 2, 0)\n",
    "            fdict[fname] = dict(sorted([(key, val) for key, val in fdict[fname].items() if key not in \"obj\"]) + [(\"obj\",fdict[fname][\"obj\"])])\n",
    "            fdict[fname][\"functions_called\"] = [fname for fname in fdict.keys() if fname + \"(\" in val[\"code_content_str\"]]\n",
    "\n",
    "    robjects.globalenv.clear()\n",
    "    return fdict\n",
    "\n",
    "\n",
    "def find_functions_called(source_path, munirflow_functions):\n",
    "    try:\n",
    "        with open(source_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            source_lines = f.readlines()\n",
    "        with open(source_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            source_str = f.read()\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Warning ! This file is not UTF-8 encoded: \" + source_path)\n",
    "        with open(source_path, \"r\", encoding=\"latin-1\") as f:\n",
    "            source_lines = f.readlines()\n",
    "        with open(source_path, \"r\", encoding=\"latin-1\") as f:\n",
    "            source_str = f.read()\n",
    "        \n",
    "    source_lines = [x.replace(\"\\n\", \"\") for x in source_lines]\n",
    "\n",
    "    f_starts = [i for i, line in enumerate(source_lines) if re.match(\"=function\\(\", line.replace(\" \", \"\").replace(\"<-\", \"=\"))]\n",
    "    if len(f_starts) > 0 and \"do_\" in os.path.basename(source_path):\n",
    "        print(\"Warning ! There are functions defined in do_*.R-file. Please define functions properly in a dedicated library file.\")\n",
    "\n",
    "    return [fname for fname in munirflow_functions if fname + \"(\" in source_str]\n",
    "\n",
    "\n",
    "def clone_repos_and_checkout_branch(git_urls, clone_path, ssh_private_path = \"~/.ssh/id_rsa\"):\n",
    "    git_ssh_identity_file = os.path.expanduser(ssh_private_path)\n",
    "    git_ssh_cmd = 'ssh -i %s' % git_ssh_identity_file\n",
    "    for user,git_dict in git_urls.items():\n",
    "        repo_name = os.path.basename(git_dict[\"git\"]).replace(\".git\", \"\")\n",
    "        local_path = os.path.join(clone_path, repo_name)\n",
    "        git_urls[user][\"local_path\"] = local_path\n",
    "        if repo_name not in os.listdir(clone_path):\n",
    "            print(\"Cloning \" + repo_name + \"...\")\n",
    "            with git.Git().custom_environment(GIT_SSH_COMMAND=git_ssh_cmd):\n",
    "                repo = git.Repo.clone_from(git_dict[\"git\"], local_path)\n",
    "        else:\n",
    "            repo = git.Repo(path=local_path)\n",
    "\n",
    "        repo.git.checkout(git_dict[\"branch\"])\n",
    "        with git.Git().custom_environment(GIT_SSH_COMMAND=git_ssh_cmd):\n",
    "            print(\"Pulling \" + repo_name + \"...\")\n",
    "            repo.git.pull()\n",
    "    print(\"Git update finished.\")\n",
    "    \n",
    "    return git_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    devtools,\n    doParallel,\n    dplyr,\n    foreach,\n    ggplot2,\n    graphics,\n    grDevices,\n    gridExtra,\n    iterators,\n    lpSolveAPI,\n    lubridate,\n    nlmrt,\n    openMalariaUtilities,\n    parallel,\n    plyr,\n    rjags,\n    rlang,\n    sp,\n    stats,\n    stringr,\n    table,\n    tidyr,\n    tidyselect,\n    utils,\n    xml2,\n"
     ]
    }
   ],
   "source": [
    "# Print libraries used in library code in a copy-pastable format, to set it to \"imports\" section in package DESCRIPTION\n",
    "libraries_used = set()\n",
    "for file_name in sorted(glob.glob(\"../R/munirflow_*.R\")):\n",
    "    if \"test\" in file_name:\n",
    "        continue\n",
    "    with open(file_name, \"r\") as f:\n",
    "        source_lines = f.read()\n",
    "    libs = re.findall(\"(?<=library\\()[^\\)]+\", source_lines)\n",
    "    requires = re.findall(\"(?<=requires\\()[^\\)]+\", source_lines)\n",
    "    imports = re.findall(r\"(?<=@import )[^\\n]+\", source_lines)\n",
    "    import_froms = re.findall(r\"(?<=@importFrom )[^\\n ]+\", source_lines)\n",
    "    colons = re.findall(\"[a-zA-Z0-9]+(?=::|:::)\", source_lines)\n",
    "    #libraries_used = libraries_used | set([x.strip() for x in libs + requires + imports + import_froms + colons])\n",
    "    libraries_used = libraries_used | set([x.strip() for x in colons])\n",
    "\n",
    "for x in sorted(libraries_used, key=str.casefold):\n",
    "    print(\"    \" + x + \",\")\n",
    "\n",
    "    import_froms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Anayzing ../R/munirflow_0_base.R\n",
      "Anayzing ../R/munirflow_1_cluster.R\n",
      "Anayzing ../R/munirflow_2_postprocess.R\n",
      "Anayzing ../R/munirflow_3_fitting.R\n",
      "Anayzing ../R/munirflow_4_local.R\n",
      "Anayzing ../R/munirflow_5_unsorted.R\n",
      "Anayzing ../R/munirflow_6_costing.R\n",
      "Pulling repo...\n",
      "Pulling om_tza...\n",
      "Pulling om-benin...\n",
      "Pulling mozsimulations...\n",
      "Git update finished.\n",
      "Skipping Munirflow.R: /home/andarin/Git/repo/Munirflow/munirflow_2_postprocess.R\n",
      "Skipping Munirflow.R: /home/andarin/Git/repo/Munirflow/munirflow_4_local.R\n",
      "Skipping Munirflow.R: /home/andarin/Git/repo/Munirflow/munirflow_1_cluster.R\n",
      "Skipping Munirflow.R: /home/andarin/Git/repo/Munirflow/munirflow_5_unsorted.R\n",
      "Skipping Munirflow.R: /home/andarin/Git/repo/Munirflow/munirflow_0_base.R\n",
      "Skipping Munirflow.R: /home/andarin/Git/repo/Munirflow/munirflow_6_costing.R\n",
      "Skipping Munirflow.R: /home/andarin/Git/repo/Munirflow/munirflow_3_fitting.R\n",
      "Skipping Munirflow.R: /home/andarin/Git/repo/Munirflow/munirflow.R\n",
      "Warning ! This file is not UTF-8 encoded: /home/andarin/Git/om-benin/do_most_BEN8_redofigures.R\n",
      "Warning ! This file is not UTF-8 encoded: /home/andarin/Git/om-benin/stratification_George.R\n",
      "Warning ! This file is not UTF-8 encoded: /home/andarin/Git/om-benin/plots_from_futrs.R\n",
      "Warning ! This file is not UTF-8 encoded: /home/andarin/Git/om-benin/extension_SMC.R\n",
      "Warning ! This file is not UTF-8 encoded: /home/andarin/Git/om-benin/maps_interventions.R\n"
     ]
    }
   ],
   "source": [
    "## Analyze Munirflow.R\n",
    "#munir_dict = analyze_library(\"../munirflow.R\")\n",
    "lib_dict = {}\n",
    "for file_name in sorted(glob.glob(\"../R/munirflow_*.R\")):\n",
    "    if \"test\" in file_name:\n",
    "        continue\n",
    "    lib_dict[file_name] = analyze_library(file_name)\n",
    "\n",
    "\n",
    "lib_dict[\"all\"] = {fname: {**fvalues, **{\"libname\": libname}} for libname, libdict in lib_dict.items() for fname, fvalues in libdict.items()}\n",
    "\n",
    "##Download all Git repos of the team to analyze which functions of Munirflow.R are used\n",
    "clone_path = \"/home/andarin/Git\"\n",
    "git_urls = {\"munir\": {\"git\": \"ssh://git@git.scicore.unibas.ch:2222/idm/countrymodelling/repo.git\", \"branch\": \"handover\", \"dir\": \"Munirflow\"},\n",
    "            \"clara\": {\"git\": \"ssh://git@git.scicore.unibas.ch:2222/idm/countrymodelling/om_tza.git\", \"branch\": \"master\", \"dir\": \"\"},\n",
    "            \"jeanne\": {\"git\": \"ssh://git@git.scicore.unibas.ch:2222/idm/countrymodelling/om-benin.git\", \"branch\": \"master\", \"dir\": \"\"},\n",
    "            \"tatiana\": {\"git\": \"ssh://git@git.scicore.unibas.ch:2222/idm/countrymodelling/mozsimulations.git\", \"branch\": \"master\", \"dir\": \"\"}\n",
    "           }\n",
    "\n",
    "git_urls = clone_repos_and_checkout_branch(git_urls, clone_path, '~/.ssh/id_rsa_stph')\n",
    "\n",
    "for user,git_dict in git_urls.items():\n",
    "    local_path_absolut = os.path.join(git_urls[user][\"local_path\"], git_urls[user][\"dir\"])\n",
    "    git_urls[user][\"files\"] = {}\n",
    "    for r_file in glob.glob(os.path.join(local_path_absolut, \"*.R\")):\n",
    "        if \"unirflow\" in os.path.basename(r_file):\n",
    "            #Ignore Munirflow.R files\n",
    "            print(\"Skipping Munirflow.R: \" + r_file)\n",
    "            continue\n",
    "        git_urls[user][\"files\"][r_file] = find_functions_called(r_file, lib_dict[\"all\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analyze which functions of Munirflow are used by whom\n",
    "\n",
    "## Create edges and nodes for the graph\n",
    "nodes = {fname: {\"file\": \"munirflow\", \"user\": \"munir\"} for fname in lib_dict[\"all\"].keys()}\n",
    "edges = []\n",
    "\n",
    "## Add internal Munirflow edges\n",
    "for fname, val in lib_dict[\"all\"].items():\n",
    "    for f_called in val[\"functions_called\"]:\n",
    "        edges += [[fname, f_called]]\n",
    "\n",
    "## Add user scripts nodes and edges\n",
    "for user,git_dict in git_urls.items():\n",
    "    for file_rec,functions_called in git_dict[\"files\"].items():\n",
    "        node_rec = user + \"/\" + os.path.basename(file_rec)\n",
    "        nodes[node_rec] = {\"file\": node_rec, \"user\": user}\n",
    "        edges += [[node_rec, fname] for fname in functions_called]\n",
    "\n",
    "## Create Graph - one node for every Munirflow function and one for each client script\n",
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_nodes_from(nodes.keys())\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "## Set default values for Munirflow.R-nodes\n",
    "for node_name in lib_dict[\"all\"].keys():\n",
    "    G.nodes[node_name].setdefault(\"used_in\", [])\n",
    "    G.nodes[node_name].setdefault(\"used_count\", 0)\n",
    "    G.nodes[node_name].setdefault(\"used_only_by_munir\", True)\n",
    "    \n",
    "for node_name,node_attrs in nodes.items():\n",
    "    G.nodes[node_name][\"file\"] = node_attrs[\"file\"]\n",
    "    if node_attrs[\"file\"] == \"munirflow\":\n",
    "        continue\n",
    "    for node_reached in nx.single_source_shortest_path(G,node_name).keys():\n",
    "        if node_reached not in lib_dict[\"all\"].keys():\n",
    "            continue\n",
    "        G.nodes[node_reached][\"used_in\"] += [node_attrs[\"file\"]]\n",
    "        G.nodes[node_reached][\"used_count\"] += 1\n",
    "        if node_attrs[\"user\"] != \"munir\":\n",
    "            G.nodes[node_reached][\"used_only_by_munir\"] = False\n",
    "\n",
    "            \n",
    "usage_dict = {node: {\"used_count\": G.nodes[node][\"used_count\"], \"used_only_by_munir\": G.nodes[node][\"used_only_by_munir\"], \"used_in\": G.nodes[node][\"used_in\"]} for node in G.nodes if G.nodes[node][\"file\"] == \"munirflow\"}\n",
    "\n",
    "for fname, fdict in usage_dict.items():\n",
    "    lib_dict[\"all\"][fname] = {**lib_dict[\"all\"][fname], **fdict}\n",
    "\n",
    "#nx.draw(G)\n",
    "#plt.savefig(\"graph.png\")\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{('batch_combine_future', 'batch_extract_outcomes'): 19, ('.do_post_process_cleanup', '.prepare_simulation_dataset'): 15, ('define_IRS', 'define_nothing'): 11, ('batch_cleanup', 'batch_process'): 8, ('define_ITN', 'define_nothing'): 8, ('define_changeHS', 'write_healthsys'): 8, ('.warn_about_bad_names', 'check_vars'): 7, ('.deploy', 'deploy_it'): 6, ('.extract_clean_futrs', '.prepare_visualization'): 6, ('.calculate_arrays_for_fitting', '.store_jags_objects'): 5, ('.calculate_arrays_for_fitting', 'view_calibration'): 5, ('.do_post_process_cleanup', '.do_post_processing'): 5, ('.do_post_processing', '.prepare_simulation_dataset'): 5, ('.do_processing_jags', 'write_JAGSmodel'): 5, ('.store_jags_objects', 'view_calibration'): 5, ('define_ITN', 'deploy_it'): 5, ('deploy_cont', 'deploy_it'): 5, ('batch_combine_future', 'batch_jags'): 4, ('batch_jags', 'batch_scenario'): 4, ('batch_malaria', 'batch_scenario'): 4, ('batch_process', 'batch_subloop'): 4, ('define_IRS', 'define_ITN'): 4, ('define_ITN', 'deploy_cont'): 4, ('define_ITN', 'make_ento'): 4, ('extract_outcomes', 'extract_outcomes_csv'): 4, ('.deploy_larv', 'deploy_it'): 3, ('.do_post_processing', 'add_idvars'): 3, ('.do_post_processing', 'batch_malaria'): 3, ('.exponential', '.weibull'): 3, ('.get_fitting_values_mean', '.view_historical_fit'): 3, ('.make_structure', '.return_OMpath'): 3, ('.write_dependency', 'batch_process'): 3, ('batch_cleanup', 'batch_extract_outcomes'): 3, ('batch_cleanup', 'batch_jags'): 3, ('batch_cleanup', 'batch_scenario'): 3, ('batch_combine_future', 'batch_malaria'): 3, ('batch_combine_future', 'batch_process'): 3, ('batch_combine_future', 'batch_scenario'): 3, ('batch_combine_future', 'batch_subloop'): 3, ('batch_extract_outcomes', 'batch_jags'): 3, ('batch_extract_outcomes', 'batch_malaria'): 3, ('batch_extract_outcomes', 'batch_process'): 3, ('batch_extract_outcomes', 'batch_scenario'): 3, ('batch_extract_outcomes', 'batch_subloop'): 3, ('batch_jags', 'batch_subloop'): 3, ('batch_malaria', 'batch_process'): 3, ('batch_malaria', 'batch_subloop'): 3, ('batch_process', 'batch_scenario'): 3, ('batch_scenario', 'batch_subloop'): 3, ('begin_vectorpop', 'end_vectorpop'): 3, ('check_cluster', 'cluster_status'): 3, ('check_cluster', 'copy_munirflow'): 3, ('cluster_status', 'copy_munirflow'): 3, ('convert_access', 'convert_cm'): 3, ('define_IRS', 'deploy_cont'): 3, ('define_IRS', 'deploy_it'): 3, ('define_nothing', 'deploy_cont'): 3, ('define_nothing', 'deploy_it'): 3, ('step1_prepare_scenario', 'step2_prepare_malaria'): 3, ('write_combine_future', 'write_extract_outcomes'): 3, ('write_scen_code', 'write_scen_data'): 3}\n"
     ]
    }
   ],
   "source": [
    "### Analyze if their are copy-pasted lines in Munirflow\n",
    "\n",
    "import Levenshtein\n",
    "cut_off = 0.9\n",
    "line_window_comparison_length = 3\n",
    "\n",
    "fname_list = sorted(lib_dict[\"all\"].keys())\n",
    "code_window_dict = {}\n",
    "\n",
    "for fname, fdict in lib_dict[\"all\"].items():\n",
    "    lines = fdict[\"code_content_str\"].split(\"\\n\")\n",
    "    line_comparison_length_real = min(line_window_comparison_length, len(lines))\n",
    "    lines_window = [re.sub(\"[ ]+\", \"\", \"\".join(lines[i:i+line_comparison_length_real])) for i in range(len(lines)-line_comparison_length_real+1)]\n",
    "    code_window_dict[fname] = lines_window\n",
    "\n",
    "similarity_dict = {}\n",
    "for i, fname1 in enumerate(fname_list):\n",
    "    for fname2 in fname_list[i+1:len(fname_list)]:\n",
    "        similarity_dict[(fname1, fname2)] = {(iwindow1,iwindow2):Levenshtein.ratio(window1, window2) for iwindow1,window1 in enumerate(code_window_dict[fname1]) for iwindow2,window2 in enumerate(code_window_dict[fname2])}\n",
    "\n",
    "similarity_cutoff_dict = {}\n",
    "for key,val in similarity_dict.items():\n",
    "    dict_rec = {\"similarity_score\": 0, \n",
    "               \"index_list\": []} \n",
    "    for index,x in val.items():\n",
    "        if x>cut_off:\n",
    "            dict_rec[\"similarity_score\"] += x\n",
    "            dict_rec[\"index_list\"] += [index]\n",
    "    if dict_rec[\"similarity_score\"] > 0:\n",
    "        dict_rec[\"similarity_score\"] = round(dict_rec[\"similarity_score\"]/0.9)+line_window_comparison_length-1\n",
    "        similarity_cutoff_dict[key] = dict_rec\n",
    "            \n",
    "\n",
    "similarity_cutoff_sorted_dict = {k: v for k, v in sorted(similarity_cutoff_dict.items(), key=lambda item: item[1][\"similarity_score\"], reverse=True)}\n",
    "print({k:v[\"similarity_score\"] for k,v in similarity_cutoff_sorted_dict.items()})\n",
    "\n",
    "\n",
    "for fname, fdict in lib_dict[\"all\"].items():\n",
    "    fdict[\"code_overlap_with\"] = []\n",
    "    lib_dict[\"all\"][fname] = fdict\n",
    "\n",
    "for (fname1, fname2), fdict in similarity_cutoff_sorted_dict.items():\n",
    "    lib_dict[\"all\"][fname1][\"code_overlap_with\"] += [(fname2, fdict[\"similarity_score\"])]\n",
    "    lib_dict[\"all\"][fname2][\"code_overlap_with\"] += [(fname1, fdict[\"similarity_score\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of lines of code in Munirflow without comments: 4325\n\nThe following functions are not used by any user and can be deleted: ['.dateToTimestep', '.define_decay', '.define_mosquito', '.exponential', '.hill', '.linear', '.smooth_compact', '.step', '.weibull', '.write_GVI_head', '.write_GVI_parameter', 'define_GVI', 'define_IPTi', 'deploy_cont', 'cancel_jobs', 'g_legend', 'goto_group', 'hard_install', 'plot_jobtime', 'save_futz', 'step1_prepare_scenario', 'step2_prepare_malaria', 'who_failed', 'step3_prepare_postprocess', '.add_EIR_zero_row', '.check_simulation_range', '.check_simulation_range_loop', '.date_today', '.join_futrs_csv', '.save_fitdat', '.separate_jags_output', 'extract_outcomes_csv', 'step4_prepare_fitting', 'visualize_prior', '.assign_core_local', '.write_local_bat_loop', '.write_local_loop', 'install_open_malaria', 'make_histvar', '.prepare_visualization', 'assign_value', 'cases', 'linearfit', 'lunique', 'seasonal_decay', 'simplefit', 'sunique', 'update_names', 'view_decay', 'add_cost', 'add_trtcost', 'unitcosts', 'wide_for_costing']\nThis will gain 686 LOC.\n\nThe following functions are only used by Munir and can probably be deprecated: ['vary_budget', 'visualize_budget']\nThis will gain 28 LOC.\n"
     ]
    }
   ],
   "source": [
    "munir_df = pd.DataFrame(lib_dict[\"all\"]).transpose().drop([\"obj\", \"code_content_str\", \"code_starts\", \"type_technical\"], axis=1)\n",
    "\n",
    "col_order = ['libname', 'code_lines_count', 'code_with_comments_lines_count', 'comments_lines_count', \n",
    " 'used_count', 'used_in', \"used_only_by_munir\",\n",
    " 'code_start', 'code_end', \n",
    " 'out', 'params', 'params_count', 'params_obligatory_count', 'params_optional_count', 'params_unused', 'functions_called', 'code_overlap_with', 'type_label', 'code_raw']\n",
    "\n",
    "munir_ordered_df = munir_df[col_order]\n",
    "\n",
    "print(\"Number of lines of code in Munirflow without comments: \" + str(munir_ordered_df[\"code_lines_count\"].sum()))\n",
    "if len(munir_ordered_df[munir_ordered_df[\"type_label\"]!=\"function\"].index) > 0:\n",
    "    print(\"\\nThere are other objects than functions defined in Munirflow!\")\n",
    "    display(munir_usage_ordered_df.groupby(\"type_label\").size().reset_index(name='counts').to_string(index=False))\n",
    "\n",
    "## Calculate unused functions:\n",
    "f_unused = munir_ordered_df[munir_ordered_df[\"used_count\"]==0]\n",
    "print(\"\\nThe following functions are not used by any user and can be deleted: \" + str(list(f_unused.index)))\n",
    "print(\"This will gain \" + str(int(f_unused[[\"code_lines_count\"]].sum()[\"code_lines_count\"])) + \" LOC.\")\n",
    "\n",
    "## Calculate TO BE DEPRECATED functions\n",
    "f_deprecatable = munir_ordered_df[(munir_ordered_df[\"used_count\"]>0) & (munir_ordered_df[\"used_only_by_munir\"])]\n",
    "print(\"\\nThe following functions are only used by Munir and can probably be deprecated: \" + str(list(f_deprecatable.index)))\n",
    "print(\"This will gain \" + str(int(f_deprecatable[[\"code_lines_count\"]].sum()[\"code_lines_count\"])) + \" LOC.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show complete table\n",
    "#display(munir_ordered_df[[\"code_lines_count\", \"comments_lines_count\", \"used_count\", \"used_only_by_munir\", \"code_overlap_with\"]].sort_values([\"code_lines_count\", \"comments_lines_count\"], ascending=False))\n",
    "\n",
    "## Save analysis DF to CSV\n",
    "munir_ordered_df.reset_index().rename(columns = {'index':'function_name'}).to_csv(\"openMalariaUtilities_analysis.csv.gz\", sep=\";\", index=False, compression='gzip')\n",
    "munir_ordered_df.reset_index().rename(columns = {'index':'function_name'}).to_excel(\"openMalariaUtilities_analysis.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}